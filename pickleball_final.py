# Pickleball Multi-View Tracking System (Final Version)
# H·ªá th·ªëng tracking ng∆∞·ªùi ch∆°i v√† b√≥ng t·ª´ 4 g√≥c camera - X·ª≠ l√Ω resize frame

import os
import cv2
import numpy as np
from ultralytics import YOLO
import time

def check_video_files():
    """Ki·ªÉm tra v√† li·ªát k√™ c√°c file video"""
    base_path = r"C:\Users\highp\pickerball"
    
    video_folders = [
        "e4e66c2058ff-0.0.0.0-3000-1-0-mzle9eCKS2oQvLJa7rOE000000",
        "e4e66c2058ff-0.0.0.0-3000-2-0-vvkoKtKIUN7KS72O4bfR000000", 
        "e4e66c2058ff-0.0.0.0-3000-3-0-a4TtYafdNkjZQjVO5hll000000",
        "e4e66c2058ff-0.0.0.0-3000-4-0-ZhV2hb2DFg8xhbXYcpWn000000"
    ]
    
    video_paths = []
    print("üîç ƒêang ki·ªÉm tra video files...")
    
    for i, folder in enumerate(video_folders):
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            mp4_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]
            if mp4_files:
                video_path = os.path.join(folder_path, mp4_files[0])
                video_paths.append(video_path)
                print(f"‚úÖ Camera {i+1}: {mp4_files[0]}")
            else:
                print(f"‚ùå Camera {i+1}: Kh√¥ng t√¨m th·∫•y file .mp4")
        else:
            print(f"‚ùå Camera {i+1}: Kh√¥ng t√¨m th·∫•y folder")
    
    return video_paths

def load_yolo_model():
    """T·∫£i YOLO model"""
    print("üîÑ ƒêang t·∫£i YOLO11 model...")
    try:
        model = YOLO('yolo11n.pt')  # S·∫Ω t·ª± ƒë·ªông download
        print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        return model
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i model: {e}")
        return None

def get_video_info(video_path):
    """L·∫•y th√¥ng tin video"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    cap.release()
    
    return {
        'fps': fps,
        'width': width,
        'height': height,
        'frame_count': frame_count,
        'duration': frame_count / fps if fps > 0 else 0
    }

def get_all_video_info(video_paths):
    """L·∫•y th√¥ng tin t·∫•t c·∫£ video"""
    all_info = []
    for i, path in enumerate(video_paths):
        info = get_video_info(path)
        if info:
            print(f"üìπ Video {i+1}: {info['width']}x{info['height']}, {info['fps']:.1f}fps")
            all_info.append(info)
        else:
            print(f"‚ùå Kh√¥ng th·ªÉ ƒë·ªçc video {i+1}")
    return all_info

def run_multi_view_detection(model, video_paths, max_frames=100):
    """Ch·∫°y detection tr√™n 4 video v·ªõi resize chu·∫©n h√≥a"""
    print(f"üé¨ B·∫Øt ƒë·∫ßu multi-view detection...")
    
    # M·ªü video captures
    caps = []
    video_infos = []
    
    for i, path in enumerate(video_paths):
        cap = cv2.VideoCapture(path)
        if not cap.isOpened():
            print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video {i+1}")
            return False
        caps.append(cap)
        
        # L·∫•y th√¥ng tin t·ª´ng video
        info = get_video_info(path)
        video_infos.append(info)
    
    # S·ª≠ d·ª•ng k√≠ch th∆∞·ªõc chu·∫©n (resize t·∫•t c·∫£ v·ªÅ c√πng k√≠ch th∆∞·ªõc)
    standard_width = 960  # Gi·∫£m ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n
    standard_height = 540
    target_fps = 30
    
    print(f"üìê Chu·∫©n h√≥a t·∫•t c·∫£ video v·ªÅ: {standard_width}x{standard_height}")
    
    # T·∫°o video writer
    output_path = 'pickleball_multiview_final.mp4'
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(
        output_path, 
        fourcc, 
        target_fps, 
        (standard_width * 2, standard_height * 2)  # 2x2 grid
    )
    
    frame_count = 0
    start_time = time.time()
    
    print(f"‚è±Ô∏è Gi·ªõi h·∫°n: {max_frames} frames")
    print(f"üé¨ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω...")
    
    try:
        while frame_count < max_frames:
            frames = []
            all_valid = True
            
            # ƒê·ªçc frame t·ª´ t·∫•t c·∫£ video
            for i, cap in enumerate(caps):
                ret, frame = cap.read()
                if not ret:
                    all_valid = False
                    break
                
                # Resize frame v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
                frame_resized = cv2.resize(frame, (standard_width, standard_height))
                frames.append(frame_resized)
            
            if not all_valid or len(frames) < 4:
                print("üìπ H·∫øt video ho·∫∑c kh√¥ng ƒë·ªß frames")
                break
            
            # Ch·∫°y detection tr√™n t·ª´ng frame
            detected_frames = []
            total_persons = 0
            total_balls = 0
            
            for i, frame in enumerate(frames):
                # YOLO detection
                results = model(
                    frame, 
                    classes=[0, 37],  # person(0) v√† sports_ball(37)
                    conf=0.25,  # Gi·∫£m confidence ƒë·ªÉ detect nhi·ªÅu h∆°n
                    verbose=False
                )
                
                # V·∫Ω k·∫øt qu·∫£ detection
                annotated_frame = results[0].plot()
                
                # Th√™m label camera
                cv2.putText(annotated_frame, f'Camera {i+1}', (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # ƒê·∫øm objects
                person_count = 0
                ball_count = 0
                if results[0].boxes is not None:
                    boxes = results[0].boxes
                    classes = boxes.cls.cpu().numpy() if boxes.cls is not None else []
                    person_count = sum(1 for cls in classes if int(cls) == 0)
                    ball_count = sum(1 for cls in classes if int(cls) == 37)
                    
                    total_persons += person_count
                    total_balls += ball_count
                    
                    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng
                    cv2.putText(annotated_frame, f'Persons: {person_count}', (10, 70),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                    cv2.putText(annotated_frame, f'Balls: {ball_count}', (10, 100),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                detected_frames.append(annotated_frame)
            
            # K·∫øt h·ª£p 4 frame th√†nh 2x2 grid
            top_row = np.hstack((detected_frames[0], detected_frames[1]))
            bottom_row = np.hstack((detected_frames[2], detected_frames[3]))
            combined = np.vstack((top_row, bottom_row))
            
            # Th√™m th√¥ng tin t·ªïng quan
            info_text = f"Frame {frame_count+1} | Total Persons: {total_persons} | Total Balls: {total_balls}"
            cv2.putText(combined, info_text, (10, standard_height * 2 - 20),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)
            
            # Ghi v√†o output
            out.write(combined)
            frame_count += 1
            
            # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô
            if frame_count % 20 == 0:
                elapsed = time.time() - start_time
                fps_processing = frame_count / elapsed
                print(f"‚è≥ Frame {frame_count}/{max_frames} - "
                      f"T·ªëc ƒë·ªô: {fps_processing:.1f} FPS - "
                      f"Persons: {total_persons}, Balls: {total_balls}")
    
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # D·ªçn d·∫πp
        print("üîÑ ƒêang d·ªçn d·∫πp...")
        for cap in caps:
            cap.release()
        out.release()
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ Ho√†n th√†nh!")
        print(f"üìä Th·ªëng k√™ x·ª≠ l√Ω:")
        print(f"   - Frames x·ª≠ l√Ω: {frame_count}")
        print(f"   - Th·ªùi gian: {total_time:.1f}s")
        print(f"   - T·ªëc ƒë·ªô trung b√¨nh: {frame_count/total_time:.1f} FPS")
        print(f"üìÅ Output video: {os.path.abspath(output_path)}")
        
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / (1024*1024)  # MB
            print(f"üíæ K√≠ch th∆∞·ªõc file: {file_size:.1f} MB")
        
        return frame_count > 0

def main():
    """H√†m main"""
    print("üèì PICKLEBALL MULTI-VIEW TRACKING SYSTEM - FINAL")
    print("=" * 55)
    
    # 1. Ki·ªÉm tra video files
    video_paths = check_video_files()
    if len(video_paths) < 4:
        print(f"‚ùå C·∫ßn 4 video, ch·ªâ t√¨m th·∫•y {len(video_paths)}")
        return
    
    # 2. Hi·ªÉn th·ªã th√¥ng tin t·∫•t c·∫£ video
    print(f"\nüìä Th√¥ng tin chi ti·∫øt video:")
    video_infos = get_all_video_info(video_paths)
    
    # 3. T·∫£i model
    model = load_yolo_model()
    if model is None:
        return
    
    # 4. Ch·∫°y multi-view detection
    print(f"\nüöÄ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω multi-view...")
    success = run_multi_view_detection(model, video_paths, max_frames=100)
    
    if success:
        print("\nüéâ TH√ÄNH C√îNG! Video multi-view ƒë√£ ƒë∆∞·ª£c t·∫°o.")
        print("üí° M·ªü file 'pickleball_multiview_final.mp4' ƒë·ªÉ xem k·∫øt qu·∫£.")
    else:
        print("\n‚ùå X·ª≠ l√Ω th·∫•t b·∫°i!")

if __name__ == "__main__":
    main()