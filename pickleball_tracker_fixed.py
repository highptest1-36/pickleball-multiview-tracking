# Pickleball Multi-View Tracking System (Fixed Version)
# H·ªá th·ªëng tracking ng∆∞·ªùi ch∆°i v√† b√≥ng t·ª´ 4 g√≥c camera

import os
import cv2
import numpy as np
from ultralytics import YOLO
import time

def check_video_files():
    """Ki·ªÉm tra v√† li·ªát k√™ c√°c file video"""
    base_path = r"C:\Users\highp\pickerball"
    
    video_folders = [
        "e4e66c2058ff-0.0.0.0-3000-1-0-mzle9eCKS2oQvLJa7rOE000000",
        "e4e66c2058ff-0.0.0.0-3000-2-0-vvkoKtKIUN7KS72O4bfR000000", 
        "e4e66c2058ff-0.0.0.0-3000-3-0-a4TtYafdNkjZQjVO5hll000000",
        "e4e66c2058ff-0.0.0.0-3000-4-0-ZhV2hb2DFg8xhbXYcpWn000000"
    ]
    
    video_paths = []
    print("üîç ƒêang ki·ªÉm tra video files...")
    
    for i, folder in enumerate(video_folders):
        folder_path = os.path.join(base_path, folder)
        if os.path.exists(folder_path):
            mp4_files = [f for f in os.listdir(folder_path) if f.endswith('.mp4')]
            if mp4_files:
                video_path = os.path.join(folder_path, mp4_files[0])
                video_paths.append(video_path)
                print(f"‚úÖ Camera {i+1}: {mp4_files[0]}")
            else:
                print(f"‚ùå Camera {i+1}: Kh√¥ng t√¨m th·∫•y file .mp4")
        else:
            print(f"‚ùå Camera {i+1}: Kh√¥ng t√¨m th·∫•y folder")
    
    return video_paths

def load_yolo_model():
    """T·∫£i YOLO model"""
    print("üîÑ ƒêang t·∫£i YOLO11 model...")
    try:
        model = YOLO('yolo11n.pt')  # S·∫Ω t·ª± ƒë·ªông download
        print("‚úÖ Model ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
        return model
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i model: {e}")
        return None

def get_video_info(video_path):
    """L·∫•y th√¥ng tin video"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    cap.release()
    
    return {
        'fps': fps,
        'width': width,
        'height': height,
        'frame_count': frame_count,
        'duration': frame_count / fps if fps > 0 else 0
    }

def run_simple_detection(model, video_paths, max_frames=200):
    """Ch·∫°y detection ƒë∆°n gi·∫£n (kh√¥ng tracking) ƒë·ªÉ tr√°nh l·ªói"""
    print(f"üé¨ B·∫Øt ƒë·∫ßu detection tr√™n {len(video_paths)} video...")
    
    # M·ªü video captures
    caps = []
    for i, path in enumerate(video_paths):
        cap = cv2.VideoCapture(path)
        if not cap.isOpened():
            print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video {i+1}")
            return False
        caps.append(cap)
    
    # L·∫•y th√¥ng tin video
    info = get_video_info(video_paths[0])
    if info is None:
        print("‚ùå Kh√¥ng th·ªÉ l·∫•y th√¥ng tin video")
        return False
    
    # T·∫°o video writer
    output_path = 'pickleball_detection_output.mp4'
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(
        output_path, 
        fourcc, 
        info['fps'], 
        (info['width'] * 2, info['height'] * 2)
    )
    
    frame_count = 0
    start_time = time.time()
    
    print(f"üìπ X·ª≠ l√Ω video: {info['width']}x{info['height']}, {info['fps']} FPS")
    print(f"‚è±Ô∏è Gi·ªõi h·∫°n: {max_frames} frames")
    
    try:
        while frame_count < max_frames:
            frames = []
            all_valid = True
            
            # ƒê·ªçc frame t·ª´ t·∫•t c·∫£ video
            for cap in caps:
                ret, frame = cap.read()
                if not ret:
                    all_valid = False
                    break
                frames.append(frame)
            
            if not all_valid or len(frames) < 4:
                print("üìπ H·∫øt video ho·∫∑c kh√¥ng ƒë·ªß frames")
                break
            
            # Ch·∫°y detection (kh√¥ng tracking) tr√™n t·ª´ng frame
            detected_frames = []
            for i, frame in enumerate(frames):
                # YOLO detection v·ªõi class person(0) v√† sports_ball(37)
                results = model(
                    frame, 
                    classes=[0, 37],  # person v√† sports_ball
                    conf=0.3,
                    verbose=False
                )
                
                # V·∫Ω k·∫øt qu·∫£ detection
                annotated_frame = results[0].plot()
                
                # Th√™m label camera
                cv2.putText(annotated_frame, f'Camera {i+1}', (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # Th√™m th√¥ng tin detection
                if results[0].boxes is not None:
                    boxes = results[0].boxes
                    classes = boxes.cls.cpu().numpy() if boxes.cls is not None else []
                    person_count = sum(1 for cls in classes if int(cls) == 0)
                    ball_count = sum(1 for cls in classes if int(cls) == 37)
                    
                    cv2.putText(annotated_frame, f'Persons: {person_count}', (10, 70),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                    cv2.putText(annotated_frame, f'Balls: {ball_count}', (10, 100),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                detected_frames.append(annotated_frame)
            
            # K·∫øt h·ª£p 4 frame th√†nh 2x2 grid
            top_row = np.hstack((detected_frames[0], detected_frames[1]))
            bottom_row = np.hstack((detected_frames[2], detected_frames[3]))
            combined = np.vstack((top_row, bottom_row))
            
            # Ghi v√†o output
            out.write(combined)
            frame_count += 1
            
            # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô
            if frame_count % 25 == 0:
                elapsed = time.time() - start_time
                fps_processing = frame_count / elapsed
                print(f"‚è≥ Frame {frame_count}/{max_frames} - T·ªëc ƒë·ªô: {fps_processing:.1f} FPS")
    
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
    
    finally:
        # D·ªçn d·∫πp
        for cap in caps:
            cap.release()
        out.release()
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ Ho√†n th√†nh!")
        print(f"üìä ƒê√£ x·ª≠ l√Ω {frame_count} frames trong {total_time:.1f}s")
        print(f"üìÅ Output: {os.path.abspath(output_path)}")
        
        return True

def run_tracking_safe(model, video_paths, max_frames=200):
    """Ch·∫°y tracking an to√†n v·ªõi bytetrack"""
    print(f"üé¨ B·∫Øt ƒë·∫ßu tracking an to√†n tr√™n {len(video_paths)} video...")
    
    # M·ªü video captures
    caps = []
    for i, path in enumerate(video_paths):
        cap = cv2.VideoCapture(path)
        if not cap.isOpened():
            print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video {i+1}")
            return False
        caps.append(cap)
    
    # L·∫•y th√¥ng tin video
    info = get_video_info(video_paths[0])
    if info is None:
        print("‚ùå Kh√¥ng th·ªÉ l·∫•y th√¥ng tin video")
        return False
    
    # T·∫°o video writer
    output_path = 'pickleball_tracking_safe.mp4'
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(
        output_path, 
        fourcc, 
        info['fps'], 
        (info['width'] * 2, info['height'] * 2)
    )
    
    frame_count = 0
    start_time = time.time()
    
    print(f"üìπ X·ª≠ l√Ω video: {info['width']}x{info['height']}, {info['fps']} FPS")
    print(f"‚è±Ô∏è Gi·ªõi h·∫°n: {max_frames} frames")
    
    # T·∫°o tracker ri√™ng cho m·ªói camera
    trackers = [YOLO('yolo11n.pt') for _ in range(4)]
    
    try:
        while frame_count < max_frames:
            frames = []
            all_valid = True
            
            # ƒê·ªçc frame t·ª´ t·∫•t c·∫£ video
            for cap in caps:
                ret, frame = cap.read()
                if not ret:
                    all_valid = False
                    break
                frames.append(frame)
            
            if not all_valid or len(frames) < 4:
                print("üìπ H·∫øt video ho·∫∑c kh√¥ng ƒë·ªß frames")
                break
            
            # Ch·∫°y tracking tr√™n t·ª´ng frame v·ªõi tracker ri√™ng
            tracked_frames = []
            for i, (frame, tracker) in enumerate(zip(frames, trackers)):
                try:
                    # S·ª≠ d·ª•ng ByteTrack v·ªõi persist=True
                    results = tracker.track(
                        frame, 
                        persist=True,
                        classes=[0, 37],  # person v√† sports_ball  
                        conf=0.3,
                        iou=0.7,
                        tracker="bytetrack.yaml",
                        verbose=False
                    )
                    
                    # V·∫Ω k·∫øt qu·∫£ tracking
                    annotated_frame = results[0].plot(labels=True, boxes=True)
                    
                except Exception as track_error:
                    print(f"‚ö†Ô∏è L·ªói tracking camera {i+1}: {track_error}")
                    # Fallback v·ªÅ detection n·∫øu tracking l·ªói
                    results = tracker(frame, classes=[0, 37], conf=0.3, verbose=False)
                    annotated_frame = results[0].plot()
                
                # Th√™m label camera
                cv2.putText(annotated_frame, f'Camera {i+1}', (10, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # Th√™m th√¥ng tin detection
                if results[0].boxes is not None:
                    boxes = results[0].boxes
                    classes = boxes.cls.cpu().numpy() if boxes.cls is not None else []
                    person_count = sum(1 for cls in classes if int(cls) == 0)
                    ball_count = sum(1 for cls in classes if int(cls) == 37)
                    
                    cv2.putText(annotated_frame, f'Persons: {person_count}', (10, 70),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                    cv2.putText(annotated_frame, f'Balls: {ball_count}', (10, 100),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                tracked_frames.append(annotated_frame)
            
            # K·∫øt h·ª£p 4 frame th√†nh 2x2 grid
            top_row = np.hstack((tracked_frames[0], tracked_frames[1]))
            bottom_row = np.hstack((tracked_frames[2], tracked_frames[3]))
            combined = np.vstack((top_row, bottom_row))
            
            # Ghi v√†o output
            out.write(combined)
            frame_count += 1
            
            # Hi·ªÉn th·ªã ti·∫øn ƒë·ªô
            if frame_count % 25 == 0:
                elapsed = time.time() - start_time
                fps_processing = frame_count / elapsed
                print(f"‚è≥ Frame {frame_count}/{max_frames} - T·ªëc ƒë·ªô: {fps_processing:.1f} FPS")
    
    except Exception as e:
        print(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
    
    finally:
        # D·ªçn d·∫πp
        for cap in caps:
            cap.release()
        out.release()
        
        total_time = time.time() - start_time
        print(f"\n‚úÖ Ho√†n th√†nh!")
        print(f"üìä ƒê√£ x·ª≠ l√Ω {frame_count} frames trong {total_time:.1f}s")
        print(f"üìÅ Output: {os.path.abspath(output_path)}")
        
        return True

def main():
    """H√†m main"""
    print("üèì PICKLEBALL MULTI-VIEW TRACKING SYSTEM")
    print("=" * 50)
    
    # 1. Ki·ªÉm tra video files
    video_paths = check_video_files()
    if len(video_paths) < 4:
        print(f"‚ùå C·∫ßn 4 video, ch·ªâ t√¨m th·∫•y {len(video_paths)}")
        return
    
    # 2. Hi·ªÉn th·ªã th√¥ng tin video
    info = get_video_info(video_paths[0])
    if info:
        print(f"\nüìä Th√¥ng tin video:")
        print(f"   - ƒê·ªô ph√¢n gi·∫£i: {info['width']}x{info['height']}")
        print(f"   - FPS: {info['fps']}")
        print(f"   - Th·ªùi l∆∞·ª£ng: {info['duration']:.1f}s")
        print(f"   - T·ªïng frames: {info['frame_count']}")
    
    # 3. T·∫£i model
    model = load_yolo_model()
    if model is None:
        return
    
    # 4. Ch·ªçn ch·∫ø ƒë·ªô
    print(f"\nüîß Ch·ªçn ch·∫ø ƒë·ªô x·ª≠ l√Ω:")
    print(f"   1. Detection ƒë∆°n gi·∫£n (nhanh, ·ªïn ƒë·ªãnh)")
    print(f"   2. Tracking an to√†n (ch·∫≠m h∆°n, c√≥ tracking ID)")
    
    # M·∫∑c ƒë·ªãnh ch·∫°y detection ƒë∆°n gi·∫£n
    mode = 1
    
    if mode == 1:
        print(f"üöÄ Ch·∫°y ch·∫ø ƒë·ªô Detection...")
        success = run_simple_detection(model, video_paths, max_frames=150)
    else:
        print(f"üöÄ Ch·∫°y ch·∫ø ƒë·ªô Tracking...")
        success = run_tracking_safe(model, video_paths, max_frames=150)
    
    if success:
        print("\nüéâ X·ª≠ l√Ω ho√†n th√†nh! Ki·ªÉm tra file output.")
    else:
        print("\n‚ùå X·ª≠ l√Ω th·∫•t b·∫°i!")

if __name__ == "__main__":
    main()